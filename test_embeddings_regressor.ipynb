{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a regressor on a set of embeddings of tweet texts\n",
    "\n",
    "Use **GetOldTweets3** library (available via Pypi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GetOldTweets3 in /home/gt/anaconda3/lib/python3.7/site-packages (0.0.11)\n",
      "Requirement already satisfied: pyquery>=1.2.10 in /home/gt/anaconda3/lib/python3.7/site-packages (from GetOldTweets3) (1.4.1)\n",
      "Requirement already satisfied: lxml>=3.5.0 in /home/gt/anaconda3/lib/python3.7/site-packages (from GetOldTweets3) (4.5.0)\n",
      "Requirement already satisfied: cssselect>0.7.9 in /home/gt/anaconda3/lib/python3.7/site-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install GetOldTweets3\n",
    "import GetOldTweets3 as got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install basilica # might have to install, if not available in underlying environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import json\n",
    "import numpy as np\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import sklearn.decomposition\n",
    "import basilica\n",
    "import pickle\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_user_name = 'LambdaSchool'\n",
    "count = 100 # during testing\n",
    "API_KEY = '7f8e7b80-be40-8936-1a61-cef3d1926786'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_to_dict(twt):\n",
    "    \"\"\"Munges a twt object into a dict, using names of attributes of\n",
    "    object as keys in dict.\n",
    "    'favorites' is a count of 'likes'\n",
    "    'hashtags' is a string that is a space-separated series of hashtags\n",
    "    'mentions' is a string that is a space-separated series of ats (@s)\n",
    "    'urls' is a string that is a space-separated series of URLs\n",
    "    \"\"\"\n",
    "    return {'date' : twt.date\n",
    "            , 'favorites' : twt.favorites\n",
    "            , 'formatted_date' : twt.formatted_date\n",
    "            , 'geo' : twt.geo\n",
    "            , 'hashtags' : twt.hashtags\n",
    "            , 'id' : twt.id\n",
    "            , 'mentions' : twt.mentions\n",
    "            , 'permalink' : twt.permalink\n",
    "            , 'replies' : twt.replies\n",
    "            , 'retweets' : twt.retweets\n",
    "            , 'text' : twt.text\n",
    "            , 'to' : twt.to\n",
    "            , 'urls' : twt.urls\n",
    "            , 'username' : twt.username}   \n",
    "\n",
    "def munge_date(dt):\n",
    "    \"\"\"Munges a datetime.datetime object into a dict, using names of attributes of\n",
    "    object as keys in dict.\n",
    "    'day_of_week' is [0-7] with 0 being 'Monday'\n",
    "    'minute_of_day' is count of minutes from midnight\"\"\"\n",
    "    return {'year' : dt.year \n",
    "            , 'month' : dt.month\n",
    "            , 'day' : dt.day\n",
    "            , 'day_of_week' : dt.weekday()\n",
    "            , 'hour' : dt.hour\n",
    "            , 'minute' : dt.minute\n",
    "            , 'minute_of_day' : (60 * dt.hour) + dt.minute}\n",
    "\n",
    "\n",
    "def join_dicts(got_tweet_object):\n",
    "    \"\"\"Returns a dict that is the result of joining \n",
    "    - a dict that is the result of parsing a GOT object\n",
    "      to  dict, and\n",
    "    - a dict that is the result of munging the a datetime.date\n",
    "      into a dict.\"\"\"\n",
    "    return {**tweet_to_dict(got_tweet_object), **munge_date(got_tweet_object.date)}\n",
    "\n",
    "def munge_tweet_objects(tweet_objects):\n",
    "    return list(map(join_dicts, tweet_objects))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving tweets via GOT3\n",
      "retrieving embeddings via basilica\n",
      "Retrieved 100 embeddings.\n"
     ]
    }
   ],
   "source": [
    "# get a set of tweets\n",
    "pickled_fn = './r_tweets.pickle'\n",
    "pickled_path = Path(pickled_fn)\n",
    "\n",
    "# if a pickled file already exists, unpickle it\n",
    "if pickled_path.is_file():\n",
    "    merged_df = pd.read_pickle(pickled_fn)\n",
    "\n",
    "# if a pickled file does not exist yet, get data then pickle it\n",
    "else:  \n",
    "    #  Create object to execute queries\n",
    "    querySpecs = got.manager.TweetCriteria().setUsername(twitter_user_name).setMaxTweets(count)\n",
    "   \n",
    "    print('Retrieving tweets via GOT3')\n",
    "    # retrieve tweets\n",
    "    retrieved_tweets = got.manager.TweetManager.getTweets(querySpecs)\n",
    "    \n",
    "    tweet_dicts = munge_tweet_objects(retrieved_tweets)\n",
    "    \n",
    "    y_retweets = pd.DataFrame.from_records(tweet_dicts,  columns=['retweets'])\n",
    "    y_retweets = y_retweets.fillna(0)\n",
    "\n",
    "    y_likes = pd.DataFrame.from_records(tweet_dicts,  columns=['likes'])\n",
    "    y_likes = y_likes.fillna(0)\n",
    "    \n",
    "    columns_not_needed = ['id', 'hashtags', 'replies', 'retweets', 'text',\n",
    "       'to', 'urls', 'year', 'month', 'day', 'date', 'formatted_date', 'permalink', 'username', 'hour', 'minute', 'geo']\n",
    "    times_df = pd.DataFrame.from_records(tweet_dicts,  exclude=columns_not_needed)\n",
    "\n",
    "    # create a df of embeddings of the texts\n",
    "    tweet_texts = [tweet.text for tweet in retrieved_tweets]\n",
    "    print('retrieving embeddings via basilica')\n",
    "    with basilica.Connection(API_KEY) as c:\n",
    "        embeddings = list(c.embed_sentences(tweet_texts))\n",
    "    print(\"Retrieved \" + str(len(embeddings)) + \" embeddings.\")\n",
    "    normalized_embeddings = sklearn.preprocessing.normalize(embeddings)\n",
    "    colnames = ['embed_col' + str(i) for i in range(len(embeddings[0]))]\n",
    "    normalized_embeddings_df = pd.DataFrame(normalized_embeddings, columns=colnames)  \n",
    "    \n",
    "    merged_df     =     pd.merge(times_df, normalized_embeddings_df, right_index=True, left_index=True)\n",
    "\n",
    "    # pickle the df\n",
    "    merged_df.to_pickle(pickled_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_retweets.values[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_likes.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colnames = ['embed_col' + str(i) for i in range(len(embeddings[0]))]\n",
    "\n",
    "# # put the normalized embeddings back in a dataframe\n",
    "# normalized_embeddings_df = pd.DataFrame(normalized_embeddings, columns=colnames)\n",
    "# # PCA the embeddings\n",
    "# # sklearn.get_config()\n",
    "# normalized_embeddings_df.shape\n",
    "\n",
    "# normalized_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into X matrix (embeddings) and y vector (retweet or like count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "False    100\n",
      "Name: favorites, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_likes = merged_df['favorites']\n",
    "print(y_likes.shape)\n",
    "print(y_likes.isna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 772)\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import sklearn.linear_model\n",
    "# import sklearn.preprocessing\n",
    "# import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = times_df\n",
    "\n",
    "X_train, X_test = sklearn.model_selection.train_test_split(X, random_state=72)\n",
    "y_retweets_train, y_retweets_test = sklearn.model_selection.train_test_split(y_retweets, random_state=72)\n",
    "\n",
    "# y_likes_train, y_likes_test = sklearn.model_selection.train_test_split(y_likes, random_state=72)\n",
    "\n",
    "# retweets_model = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "# retweets_model.fit(X_train, y_retweets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-49a292136bb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlikes_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlikes_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_likes_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "likes_model = sklearn.linear_model.LogisticRegression(max_iter=100)\n",
    "likes_model.fit(X_train, y_likes_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Retweets Train accuracy: %.3f' % retweets_model.score(X_train, y_retweets_train))\n",
    "print('Retweets Test accuracy: %.3f' % retweets_model.score(X_test, y_retweets_test))\n",
    "\n",
    "print('Likes Train accuracy: %.3f' % likes_model.score(X_train, y_likes_train))\n",
    "print('Likes Test accuracy: %.3f' % likes_model.score(X_test, y_likes_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_retweets[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_retweets_one_embedding(embdng):\n",
    "    \"\"\"Use model to predict based on one embedding.\"\"\"\n",
    "    return retweets_model.predict(embdng)[0]\n",
    "\n",
    "def predict_retweets_one_by_index(embeddings_array, idx):\n",
    "    \"\"\"Use model to predict based on one embedding,\n",
    "    selected by index from a list of embeddings.\"\"\"\n",
    "    return ('predicted retweets', \n",
    "            predict_retweets_one_embedding(embeddings_array[idx].reshape(1,-1)), \n",
    "            'actual', y_retweets[idx])\n",
    "\n",
    "\n",
    "def predict_likes_one_embedding(embdng):\n",
    "    \"\"\"Use model to predict based on one embedding.\"\"\"\n",
    "    return likes_model.predict(embdng)[0]\n",
    "\n",
    "def predict_likes_one_by_index(embeddings_array, idx):\n",
    "    \"\"\"Use model to predict based on one embedding,\n",
    "    selected by index from a list of embeddings.\"\"\"\n",
    "    return  ('predicted likes', \n",
    "             predict_likes_one_embedding(embeddings_array[idx].reshape(1,-1)),\n",
    "             y_likes[idx])\n",
    "             \n",
    "\n",
    "foo = merged_df.values\n",
    "predict_retweets_one_by_index(foo,5)\n",
    "predict_likes_one_by_index(foo,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
