{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SoMe_NLP_Topic_Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QP2eBScy8E7s"
      },
      "source": [
        "#SoMe Topic Modeling Notebook | Release canvas 1 📖"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mnD3BnPPcKDo"
      },
      "source": [
        "## Installations and Libraries 💽"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3nu7UwHACMTs",
        "colab": {}
      },
      "source": [
        "import time \n",
        "# Time the running of everything\n",
        "start_of_notebook_time = time.time()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0k6aior36cIh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6f2c5b2-4f10-40fa-98a5-559a99be5637"
      },
      "source": [
        "# Installations\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    !pip install emoji --upgrade\n",
        "    !pip install pandas-profiling==2.*\n",
        "    !pip install plotly==4.*\n",
        "    !python -m spacy download en_core_web_lg\n",
        "    !pip install pyldavis\n",
        "    !pip install gensim\n",
        "    !pip install chart_studio\n",
        "    #!pip install --upgrade autopep8"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n",
            "\r\u001b[K     |██████▍                         | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 40kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49716 sha256=150b1d01e7101aff78cce81e4de210bd374495f66d17e6375a7f2b846ea82128\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.6.0\n",
            "Collecting pandas-profiling==2.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/79/5d03ed1172e3e67a997a6a795bcdd2ab58f84851969d01a91455383795b6/pandas_profiling-2.9.0-py2.py3-none-any.whl (258kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets>=7.5.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (7.5.1)\n",
            "Collecting htmlmin>=0.1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting confuse>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/6d/bedc0d1068bd244cee05843313cbec6cebb9f01f925538269bababc6d887/confuse-1.3.0-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (2.11.2)\n",
            "Collecting tangled-up-in-unicode>=0.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/e2/e588ab9298d4989ce7fdb2b97d18aac878d99dbdc379a4476a09d9271b68/tangled_up_in_unicode-0.0.6-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (1.0.5)\n",
            "Collecting visions[type_image_path]==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e3/9416e94e767d59a86edcbcb8e1c8f42874d272c3b343676074879e9db0e0/visions-0.5.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (1.4.1)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (20.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (1.18.5)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (2.23.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (3.2.2)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (0.4.2)\n",
            "Collecting phik>=0.9.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/5a/7ef1c04ce62cd72f900c06298dc2385840550d5c653a0dbc19109a5477e6/phik-0.10.0-py3-none-any.whl (599kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 56.0MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.43.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/d5/f220e0c69b2f346b5649b66abebb391df1a00a59997a7ccf823325bd7a3e/tqdm-4.49.0-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (0.10.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.*) (4.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.*) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.*) (5.0.7)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.*) (4.10.1)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.*) (5.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling==2.*) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.11.1->pandas-profiling==2.*) (1.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling==2.*) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling==2.*) (2.8.1)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.5.0->pandas-profiling==2.*) (2.5)\n",
            "Collecting imagehash; extra == \"type_image_path\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/5d/cc81830be3c4705a46cdbca74439b67f1017881383ba0127c41c4cecb7b3/ImageHash-4.1.0.tar.gz (291kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 54.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow; extra == \"type_image_path\" in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.5.0->pandas-profiling==2.*) (7.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling==2.*) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling==2.*) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling==2.*) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling==2.*) (3.0.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.*) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.*) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.*) (2.4.7)\n",
            "Requirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.10->pandas-profiling==2.*) (0.48.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets>=7.5.1->pandas-profiling==2.*) (4.4.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets>=7.5.1->pandas-profiling==2.*) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets>=7.5.1->pandas-profiling==2.*) (1.15.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (5.3.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (4.6.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (2.6.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.*) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.*) (5.3.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.*) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.*) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.*) (50.3.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.*) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.*) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.*) (1.0.18)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.5.0->pandas-profiling==2.*) (1.1.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.10->pandas-profiling==2.*) (0.31.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (0.8.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (1.5.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.*) (19.0.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.*) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.*) (0.2.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (3.1.5)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (1.4.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.*) (20.4)\n",
            "Building wheels for collected packages: htmlmin, imagehash\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27085 sha256=408f2c98a782e3407f5765d1387acbfee29a0595289b239b0687056ae4927f88\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for imagehash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagehash: filename=ImageHash-4.1.0-py2.py3-none-any.whl size=291991 sha256=42021674ce89690b730930b5bc913a17889b77b563021cd301adf839a9234f5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/1c/dc/6831446f09feb8cc199ec73a0f2f0703253f6ae013a22f4be9\n",
            "Successfully built htmlmin imagehash\n",
            "Installing collected packages: htmlmin, confuse, tangled-up-in-unicode, imagehash, visions, phik, tqdm, pandas-profiling\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "Successfully installed confuse-1.3.0 htmlmin-0.1.12 imagehash-4.1.0 pandas-profiling-2.9.0 phik-0.10.0 tangled-up-in-unicode-0.0.6 tqdm-4.49.0 visions-0.5.0\n",
            "Requirement already satisfied: plotly==4.* in /usr/local/lib/python3.6/dist-packages (4.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.*) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly==4.*) (1.15.0)\n",
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.49.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180944 sha256=e2584696575108c1da64a50fa0c6059ef1b11fc3b81d94aae9f15c523e598012\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b139nepz/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "Collecting pyldavis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyldavis) (0.35.1)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyldavis) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyldavis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyldavis) (1.0.5)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyldavis) (0.16.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyldavis) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyldavis) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyldavis) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyldavis) (0.16.0)\n",
            "Collecting funcy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 33.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyldavis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyldavis) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyldavis) (1.1.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyldavis) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyldavis) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyldavis) (50.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyldavis) (8.5.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyldavis) (20.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyldavis) (1.15.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyldavis) (1.9.0)\n",
            "Building wheels for collected packages: pyldavis, funcy\n",
            "  Building wheel for pyldavis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyldavis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=8655365f629f62c0222f7942f82bf7251127080331d33d169f9120b3dbb21a1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for funcy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32042 sha256=f9791a8bfc3f3dda6acf6e290b67c47a5290b84c2d6a5b2aeca22954327bc5a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/5a/d8/1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\n",
            "Successfully built pyldavis funcy\n",
            "Installing collected packages: funcy, pyldavis\n",
            "Successfully installed funcy-1.14 pyldavis-2.1.2\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.1.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.59)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.59 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.59)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.59->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.59->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n",
            "Collecting chart_studio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ce/330794a6b6ca4b9182c38fc69dd2a9cbff60fd49421cb8648ee5fee352dc/chart_studio-1.1.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from chart_studio) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from chart_studio) (4.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from chart_studio) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from chart_studio) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (2020.6.20)\n",
            "Installing collected packages: chart-studio\n",
            "Successfully installed chart-studio-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HzBjmwNq7X7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f58526f9-9601-434b-81c4-db06916b44b9"
      },
      "source": [
        "# Required Libraries\n",
        "\n",
        "#Base and Cleaning \n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import emoji\n",
        "import regex\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "#Visualizations\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import pyLDAvis.gensim\n",
        "import chart_studio\n",
        "import chart_studio.plotly as py \n",
        "import chart_studio.tools as tls\n",
        "\n",
        "#Natural Language Processing (NLP)\n",
        "import spacy\n",
        "import gensim\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.ldamulticore import LdaMulticore\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.parsing.preprocessing import STOPWORDS as SW\n",
        "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pprint import pprint\n",
        "from wordcloud import STOPWORDS\n",
        "stopwords = set(STOPWORDS)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning:\n",
            "\n",
            "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/_pytest/mark/structures.py:426: DeprecationWarning:\n",
            "\n",
            "The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning:\n",
            "\n",
            "`scipy.sparse.sparsetools` is deprecated!\n",
            "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c3Q_P-053noK",
        "colab": {}
      },
      "source": [
        "#Setting up chart studios to save visualizations\n",
        "Username = 'so-me'\n",
        "api_key = 'MnGv47xSLbpMq7mDjvLT'\n",
        "\n",
        "chart_studio.tools.set_credentials_file(username=Username, api_key=api_key)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLHPwUWbfSON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E82Pktqa8Is-"
      },
      "source": [
        "##Data Cleaning 🧹"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "455gjE5478et",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "a6b75a9a-3e5b-4640-a374-1e55227d6d9f"
      },
      "source": [
        "# Loading the JSON file \n",
        "url_elon = 'https://raw.githubusercontent.com/Lambda-School-Labs/social-media-strategy-ds/feature/topic/python_notebooks/elonmusk_followers_english.json'\n",
        "url_dutchbros = 'https://raw.githubusercontent.com/Lambda-School-Labs/social-media-strategy-ds/feature/topic/python_notebooks/dutchbros_followers.json'\n",
        "\n",
        "df = requests.get(url_elon).json()\n",
        "\n",
        "# Converting the dataset to pandas DataFrame and renaming the columns \n",
        "df = pd.DataFrame(df.values())\n",
        "df = df.rename(columns={0:'original_tweets'})\n",
        "\n",
        "#Removing emojies from text\n",
        "#Refrence 1 : https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
        "#Refrence 2 : https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python\n",
        "\n",
        "def give_emoji_free_text(text):\n",
        "    \"\"\"\n",
        "    Removes emoji's from tweets\n",
        "    Accepts:\n",
        "        Text (tweets)\n",
        "    Returns:\n",
        "        Text (emoji free tweets)\n",
        "    \"\"\"\n",
        "    emoji_list = [c for c in text if c in emoji.UNICODE_EMOJI]\n",
        "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
        "    return clean_text\n",
        "\n",
        "def url_free_text(text):\n",
        "    '''\n",
        "    Cleans text from urls\n",
        "    '''\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    return text\n",
        "\n",
        "# Apply the function above and get tweets free of emoji's\n",
        "call_emoji_free = lambda x: give_emoji_free_text(x)\n",
        "\n",
        "# Apply `call_emoji_free` which calls the function to remove all emoji's\n",
        "df['emoji_free_tweets'] = df['original_tweets'].apply(call_emoji_free)\n",
        "\n",
        "#Create a new column with url free tweets\n",
        "df['url_free_tweets'] = df['emoji_free_tweets'].apply(url_free_text)\n",
        "\n",
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_tweets</th>\n",
              "      <th>emoji_free_tweets</th>\n",
              "      <th>url_free_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This kid will forever be a legend 😂 https://t....</td>\n",
              "      <td>This kid will forever be a legend https://t.co...</td>\n",
              "      <td>This kid will forever be a legend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you truly believe Lebrons mindset, competit...</td>\n",
              "      <td>If you truly believe Lebrons mindset, competit...</td>\n",
              "      <td>If you truly believe Lebrons mindset, competit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BUTTLICKER! OUR PRICES HAVE NEVER BEEN LOWER!!!</td>\n",
              "      <td>BUTTLICKER! OUR PRICES HAVE NEVER BEEN LOWER!!!</td>\n",
              "      <td>BUTTLICKER! OUR PRICES HAVE NEVER BEEN LOWER!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Bhuvan_Bam ❤️❤️</td>\n",
              "      <td>@Bhuvan_Bam</td>\n",
              "      <td>@Bhuvan_Bam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm not crying you're crying.\\nhttps://t.co/Bc...</td>\n",
              "      <td>I'm not crying you're crying. https://t.co/BcF...</td>\n",
              "      <td>I'm not crying you're crying.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9941</th>\n",
              "      <td>@MirandaSleeper The offerings in that f-3 are ...</td>\n",
              "      <td>@MirandaSleeper The offerings in that f-3 are ...</td>\n",
              "      <td>@MirandaSleeper The offerings in that f-3 are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9942</th>\n",
              "      <td>This will be the defining segment of “The Last...</td>\n",
              "      <td>This will be the defining segment of “The Last...</td>\n",
              "      <td>This will be the defining segment of “The Last...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9943</th>\n",
              "      <td>@frank_miskelly I don’t like it, I LOVE IT! Bu...</td>\n",
              "      <td>@frank_miskelly I don’t like it, I LOVE IT! Bu...</td>\n",
              "      <td>@frank_miskelly I don’t like it, I LOVE IT! Bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9944</th>\n",
              "      <td>Excited for my brother @Shufly10 as he embarks...</td>\n",
              "      <td>Excited for my brother @Shufly10 as he embarks...</td>\n",
              "      <td>Excited for my brother @Shufly10 as he embarks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9945</th>\n",
              "      <td>Congrats to @shufly10 on being named offensive...</td>\n",
              "      <td>Congrats to @shufly10 on being named offensive...</td>\n",
              "      <td>Congrats to @shufly10 on being named offensive...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9946 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        original_tweets  ...                                    url_free_tweets\n",
              "0     This kid will forever be a legend 😂 https://t....  ...                 This kid will forever be a legend \n",
              "1     If you truly believe Lebrons mindset, competit...  ...  If you truly believe Lebrons mindset, competit...\n",
              "2       BUTTLICKER! OUR PRICES HAVE NEVER BEEN LOWER!!!  ...    BUTTLICKER! OUR PRICES HAVE NEVER BEEN LOWER!!!\n",
              "3                                      @Bhuvan_Bam ❤️❤️  ...                                        @Bhuvan_Bam\n",
              "4     I'm not crying you're crying.\\nhttps://t.co/Bc...  ...                     I'm not crying you're crying. \n",
              "...                                                 ...  ...                                                ...\n",
              "9941  @MirandaSleeper The offerings in that f-3 are ...  ...  @MirandaSleeper The offerings in that f-3 are ...\n",
              "9942  This will be the defining segment of “The Last...  ...  This will be the defining segment of “The Last...\n",
              "9943  @frank_miskelly I don’t like it, I LOVE IT! Bu...  ...  @frank_miskelly I don’t like it, I LOVE IT! Bu...\n",
              "9944  Excited for my brother @Shufly10 as he embarks...  ...  Excited for my brother @Shufly10 as he embarks...\n",
              "9945  Congrats to @shufly10 on being named offensive...  ...  Congrats to @shufly10 on being named offensive...\n",
              "\n",
              "[9946 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PRXDrK6PJyw-"
      },
      "source": [
        "##Tokenizing 🕵🏻‍♂"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fI9vVu-M8wrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "4062a784-a8b8-4e6e-9106-14007452da63"
      },
      "source": [
        "# Load spacy\n",
        "# Make sure to restart the runtime after running installations and libraries tab\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-223ea9594184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load spacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Make sure to restart the runtime after running installations and libraries tab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_lg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e0XL-j0z9REI",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Import Gensim and Wordcloud to use their stopwords as well and use the combined stopwords of ALL as the variable:\n",
        "ALL_STOP_WORDS\n",
        "\"\"\"\n",
        "# Timing Start\n",
        "program_start_time = time.time()\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer(nlp.vocab)\n",
        "\n",
        "\n",
        "# Custom stopwords\n",
        "custom_stopwords = ['hi','\\n','\\n\\n', '&amp;', ' ', '.', '-', 'got', \"it's\", 'it’s', \"i'm\", 'i’m', 'im', 'want', 'like', '$', '@']\n",
        "\n",
        "# Customize stop words by adding to the default list\n",
        "STOP_WORDS = nlp.Defaults.stop_words.union(custom_stopwords)\n",
        "\n",
        "# ALL_STOP_WORDS = spacy + gensim + wordcloud\n",
        "ALL_STOP_WORDS = STOP_WORDS.union(SW).union(stopwords)\n",
        "\n",
        "\n",
        "tokens = []\n",
        "\n",
        "for doc in tokenizer.pipe(df['url_free_tweets'], batch_size=500):\n",
        "    doc_tokens = []    \n",
        "    for token in doc: \n",
        "        if token.text.lower() not in STOP_WORDS:\n",
        "            doc_tokens.append(token.text.lower())   \n",
        "    tokens.append(doc_tokens)\n",
        "\n",
        "# Makes tokens column\n",
        "df['tokens'] = tokens\n",
        "\n",
        "# Timing End\n",
        "program_end_time = time.time()\n",
        "\n",
        "# View df\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jqYjmsit8baV",
        "colab": {}
      },
      "source": [
        "# See how long it took\n",
        "print(program_end_time - program_start_time, \"seconds to finish\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lOnjLgfL_m6P"
      },
      "source": [
        "##Lemmatization🇬🇧"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zw5AKLMf9gS7",
        "colab": {}
      },
      "source": [
        "# Refrence 4 : https://stackoverflow.com/questions/45306988/column-of-lists-convert-list-to-string-as-a-new-column\n",
        "\n",
        "# Timing Start\n",
        "program_start_time = time.time()\n",
        "\n",
        "# Make tokens a string again\n",
        "df['tokens_back_to_text'] = [' '.join(map(str, l)) for l in df['tokens']]\n",
        "\n",
        "def get_lemmas(text):\n",
        "    '''Used to lemmatize the processed tweets'''\n",
        "    lemmas = []\n",
        "    \n",
        "    doc = nlp(text)\n",
        "    \n",
        "    # Something goes here :P\n",
        "    for token in doc: \n",
        "        if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_ != 'PRON'):\n",
        "            lemmas.append(token.lemma_)\n",
        "    \n",
        "    return lemmas\n",
        "\n",
        "df['lemmas'] = df['tokens_back_to_text'].apply(get_lemmas)\n",
        "\n",
        "# Make lemmas a string again\n",
        "df['lemmas_back_to_text'] = [' '.join(map(str, l)) for l in df['lemmas']]\n",
        "# df[['original_tweet', 'lemmas_back_to_text']]\n",
        "\n",
        "# Timing End\n",
        "program_end_time = time.time()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QpmLlCkl83lC",
        "colab": {}
      },
      "source": [
        "#Printing Lemmetization Time\n",
        "print(program_end_time - program_start_time, \"seconds to finish\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2UO-6fIX_tTA",
        "colab": {}
      },
      "source": [
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Timing Start\n",
        "program_start_time = time.time()\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer(nlp.vocab)\n",
        "\n",
        "# Tokenizer function\n",
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    Parses a string into a list of semantic units (words)\n",
        "    Args:\n",
        "        text (str): The string that the function will tokenize.\n",
        "    Returns:\n",
        "        list: tokens parsed out\n",
        "    \"\"\"\n",
        "    # Removing url's\n",
        "    pattern = r\"http\\S+\"\n",
        "    \n",
        "    tokens = re.sub(pattern, \"\", text) # https://www.youtube.com/watch?v=O2onA4r5UaY\n",
        "    tokens = re.sub('[^a-zA-Z 0-9]', '', text)\n",
        "    tokens = re.sub('[%s]' % re.escape(string.punctuation), '', text) # Remove punctuation\n",
        "    tokens = re.sub('\\w*\\d\\w*', '', text) # Remove words containing numbers\n",
        "    tokens = re.sub('@*!*\\$*', '', text) # Remove @ ! $\n",
        "    tokens = tokens.strip(',') # TESTING THIS LINE\n",
        "    tokens = tokens.strip('?') # TESTING THIS LINE\n",
        "    tokens = tokens.strip('!') # TESTING THIS LINE\n",
        "    tokens = tokens.strip(\"'\") # TESTING THIS LINE\n",
        "    tokens = tokens.strip(\".\") # TESTING THIS LINE\n",
        "\n",
        "    tokens = tokens.lower().split() # Make text lowercase and split it\n",
        "    \n",
        "    return tokens\n",
        "\n",
        "# Apply tokenizer\n",
        "df['lemma_tokens'] = df['lemmas_back_to_text'].apply(tokenize)\n",
        "\n",
        "# Timing End\n",
        "program_end_time = time.time()\n",
        "\n",
        "# View those tokens (the 4th column)\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TTd2CJ5O9Xsx",
        "colab": {}
      },
      "source": [
        "#Printing Tokenization Time\n",
        "print(program_end_time - program_start_time, \"seconds to finish\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mB58CgA89KMA"
      },
      "source": [
        "##Topic Modeling ㊙️"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RT6ZG-aTAN04"
      },
      "source": [
        "###id2word 📒"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FL1wBl_BANh1",
        "colab": {}
      },
      "source": [
        "# Create a id2word dictionary\n",
        "id2word = Dictionary(df['lemma_tokens'])\n",
        "print(len(id2word))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aUINWoDUASMU",
        "colab": {}
      },
      "source": [
        "# Filtering Extremes\n",
        "id2word.filter_extremes(no_below=2, no_above=.99)\n",
        "print(len(id2word))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b9Io9q5ZAoIp"
      },
      "source": [
        "###Corpus Object & Generating Base Model Topics 📚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I67SGEfAAlOF",
        "colab": {}
      },
      "source": [
        "# Creating a corpus object \n",
        "corpus = [id2word.doc2bow(d) for d in df['lemma_tokens']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ATCdp1cUfVzX"
      },
      "source": [
        "####Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AS-sCZ36As2s",
        "colab": {}
      },
      "source": [
        "# Timing Start\n",
        "base_model_program_start_time = time.time()\n",
        "\n",
        "# Instantiating a LDA model \n",
        "base_model = LdaMulticore(corpus=corpus, num_topics=5, id2word=id2word, workers=12, passes=5)\n",
        "\n",
        "# Timing End\n",
        "base_model_program_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KoA8pLx19vK4",
        "colab": {}
      },
      "source": [
        "#Printing First Model Time\n",
        "base_model_runtime = round(base_model_program_end_time - base_model_program_start_time, 2)\n",
        "print(base_model_runtime)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "--nhlwv3Ayf5",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in base_model.print_topics()]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N2RmjsSAA0LV",
        "colab": {}
      },
      "source": [
        "# Create Topics\n",
        "topics = [' '.join(t[0:10]) for t in words]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5mQy-jkDA6F2",
        "colab": {}
      },
      "source": [
        "# Getting the topics\n",
        "for id, t in enumerate(topics): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n14m0k2i_jhu",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "base_perplexity = base_model.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', base_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model = CoherenceModel(model=base_model, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_base = coherence_model.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_base)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CW2DtdUfBKBw"
      },
      "source": [
        "#### Base Model Topic Distance Visualization 📈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p-53CvTHA95-",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(base_model, corpus, id2word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EblzT9pPRcMK"
      },
      "source": [
        "###Grid Seach 🔍"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IlIQoT3C7s2Y",
        "colab": {}
      },
      "source": [
        "lemmas_df = df['lemmas_back_to_text']\n",
        "print(type(lemmas_df[0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ls3FDkLF8qCz",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "data_vectorized = vectorizer.fit_transform(df['lemmas_back_to_text'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Sm2THjI8qmi",
        "colab": {}
      },
      "source": [
        "gs_start_time = time.time()\n",
        "\n",
        "# Define Search Param\n",
        "search_params = {'n_components': [10, 15, 20, 25, 30], 'learning_decay': [.5, .7, .9]}\n",
        "\n",
        "# Init the Model\n",
        "lda = LatentDirichletAllocation()\n",
        "\n",
        "# Init Grid Search Class\n",
        "model = GridSearchCV(lda, param_grid=search_params)\n",
        "\n",
        "# Do the Grid Search\n",
        "model.fit(data_vectorized)\n",
        "GridSearchCV(cv=None, error_score='raise',\n",
        "             estimator=LatentDirichletAllocation(batch_size=128, \n",
        "                                                 doc_topic_prior=None,\n",
        "                                                 evaluate_every=-1, \n",
        "                                                 learning_decay=0.7, \n",
        "                                                 learning_method=None,\n",
        "                                                 learning_offset=10.0, \n",
        "                                                 max_doc_update_iter=100, \n",
        "                                                 max_iter=10,\n",
        "                                                 mean_change_tol=0.001, \n",
        "                                                 n_components=10, \n",
        "                                                 n_jobs=1,\n",
        "                                                 perp_tol=0.1, \n",
        "                                                 random_state=None,\n",
        "                                                 topic_word_prior=None, \n",
        "                                                 total_samples=1000000.0, \n",
        "                                                 verbose=0),\n",
        "             iid=True, n_jobs=1,\n",
        "             param_grid={'n_topics': [10, 15, 20, 30], \n",
        "                         'learning_decay': [0.5, 0.7, 0.9]},\n",
        "             pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
        "             scoring=None, verbose=0)\n",
        "\n",
        "gs_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFdwcHDP83iV",
        "colab": {}
      },
      "source": [
        "print(gs_end_time - gs_start_time, \"seconds to finish\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xzyBIDzC84NP",
        "colab": {}
      },
      "source": [
        "# Best Model\n",
        "best_lda_model = model.best_estimator_\n",
        "\n",
        "# Model Parameters\n",
        "print(\"Best Model's Params: \", model.best_params_)\n",
        "\n",
        "# Log Likelihood Score\n",
        "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
        "\n",
        "# Perplexity\n",
        "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))\n",
        "# Best Model's Params:  {'learning_decay': 0.9, 'n_topics': 10}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WTEv5NSJKrWV"
      },
      "source": [
        "###Hyperparameter Tuning 🦾"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tLtl_I-LGRLD"
      },
      "source": [
        "####Model iteration 1 (number of topics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1betn6GoJMsY"
      },
      "source": [
        "#####1.0 Topics = 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7sRH5tc-JU89",
        "colab": {}
      },
      "source": [
        "# Let's start with parameter tuning for the LDA model and,\n",
        "# find an optimal number of topics to reach the best coherence score\n",
        "\n",
        "# Define chunksize and passes\n",
        "# Chunksize is Number of documents to be used in each training chunk\n",
        "# Passes is Number of passes through the corpus during training\n",
        "\n",
        "# Timing Start\n",
        "model_1_0_start_time = time.time()\n",
        "\n",
        "model_1_0 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=5,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=10)\n",
        "\n",
        "# Timing End\n",
        "model_1_0_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HpxgR7GtJYTW",
        "colab": {}
      },
      "source": [
        "#Printing First Model Time\n",
        "model_1_0_runtime = round(model_1_0_end_time - model_1_0_start_time, 2)\n",
        "print(model_1_0_runtime)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dah3J5wOKTEq",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_1_0 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_1_0.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_1_0 = [' '.join(t[0:10]) for t in words_1_0]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_1_0): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EhHWl2GpK2mX",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_1_0_perplexity = model_1_0.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_1_0_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_1_0 = CoherenceModel(model=model_1_0, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_1_0 = coherence_model_1_0.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_1_0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E8LhXv7oK20B",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_1_0, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MvIMwB-um5qo"
      },
      "source": [
        "#####1.1 Topics = 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kua_Nbg2BNBV",
        "colab": {}
      },
      "source": [
        "#Increasing number of topics to 10\n",
        "#Timing Start\n",
        "model_1_1_start_time = time.time()\n",
        "\n",
        "model_1_1 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=10,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=10)\n",
        "\n",
        "# Timing End\n",
        "model_1_1_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gavxFwmw_Y4v",
        "colab": {}
      },
      "source": [
        "#Printing First Model Time\n",
        "model_1_1_runtime = round(model_1_1_end_time - model_1_1_start_time, 2)\n",
        "print(model_1_1_runtime)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wY2tDxQmWeGE",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_1_1 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_1_1.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_1_1 = [' '.join(t[0:10]) for t in words_1_1]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_1_1): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OOFhtpyHAPl2",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_1_1_perplexity = model_1_1.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_1_1_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_1_1 = CoherenceModel(model=model_1_1, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_1_1 = coherence_model_1_1.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_1_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D_Nb5OzA_sh4",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_1_1, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VQ8DCnDhnHSt"
      },
      "source": [
        "#####1.2 Topics = 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S9--K2vPIQck",
        "colab": {}
      },
      "source": [
        "#Increasing number of topics to 15\n",
        "#Timing Start\n",
        "model_1_2_start_time = time.time()\n",
        "\n",
        "model_1_2 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=15,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=10)\n",
        "\n",
        "# Timing End\n",
        "model_1_2_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T0M46OppIRQh",
        "colab": {}
      },
      "source": [
        "#Printing First Model Time\n",
        "model_1_2_runtime = round(model_1_2_end_time - model_1_2_start_time, 2)\n",
        "print(model_1_2_runtime)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j_53r-34Pubg",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_1_2 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_1_2.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_1_2 = [' '.join(t[0:10]) for t in words_1_2]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_1_2): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RPLiC_ISPy4T",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_1_2_perplexity = model_1_2.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_1_2_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_1_2 = CoherenceModel(model=model_1_2, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_1_2 = coherence_model_1_2.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_1_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VATakze5P3UV",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_1_2, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GHqpaCo9nSCF"
      },
      "source": [
        "##### 1.3 Topics = 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FrApryy3RN5h",
        "colab": {}
      },
      "source": [
        "#Increasing number of topics to 20\n",
        "#Timing Start\n",
        "model_1_3_start_time = time.time()\n",
        "\n",
        "model_1_3 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=20,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=10)\n",
        "\n",
        "# Timing End\n",
        "model_1_3_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f5ISnpnuROgz",
        "colab": {}
      },
      "source": [
        "#Printing First Model Time\n",
        "model_1_3_runtime = round(model_1_3_end_time - model_1_3_start_time, 2)\n",
        "print(model_1_3_runtime)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bz933FaHROqa",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_1_3 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_1_3.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_1_3 = [' '.join(t[0:10]) for t in words_1_3]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_1_3): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6c7uv5I1ROu3",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_1_3_perplexity = model_1_3.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_1_3_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_1_3 = CoherenceModel(model=model_1_3, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_1_3 = coherence_model_1_3.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_1_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v2T_eL9VROz5",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_1_3, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AmU6wXz0nX3g"
      },
      "source": [
        "##### 1.4 Topics = 25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0g0eyqRzSbsn",
        "colab": {}
      },
      "source": [
        "#Increasing number of topics to 25\n",
        "#Timing Start\n",
        "model_1_4_start_time = time.time()\n",
        "\n",
        "model_1_4 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=25,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=10)\n",
        "\n",
        "# Timing End\n",
        "model_1_4_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jS3iH1KFSgH0",
        "colab": {}
      },
      "source": [
        "#Printing First Model Time\n",
        "model_1_4_runtime = round(model_1_4_end_time - model_1_4_start_time, 2)\n",
        "print(model_1_4_runtime)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kcS2f_YJSkQz",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_1_4 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_1_4.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_1_4 = [' '.join(t[0:10]) for t in words_1_3]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_1_4): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rqSS38PBSvI_",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_1_4_perplexity = model_1_4.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_1_4_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_1_4 = CoherenceModel(model=model_1_4, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_1_4 = coherence_model_1_4.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_1_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7uW0DLKaTD3B",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_1_4, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PLY8XYAsna5g"
      },
      "source": [
        "#####1.5 Topics = 30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MwdHJbdXTXbe",
        "colab": {}
      },
      "source": [
        "#We have had a reduction from .39 to .35 in coherence score \n",
        "#by going from 20 to 25. Let's try 30 topics and see what \n",
        "#coherence score we'll get. \n",
        "\n",
        "# Timing Start\n",
        "model_1_5_start_time = time.time()\n",
        "\n",
        "model_1_5 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=30,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=10)\n",
        "\n",
        "# Timing End\n",
        "model_1_5_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JcdSchKuTXYB",
        "colab": {}
      },
      "source": [
        "#Printing First Model Time\n",
        "model_1_5_runtime = round(model_1_5_end_time - model_1_5_start_time, 2)\n",
        "print(model_1_5_runtime)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2e7BCZHATXUC",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_1_5 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_1_5.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_1_5 = [' '.join(t[0:10]) for t in words_1_5]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_1_5): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t8TsERtFTWjH",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_1_5_perplexity = model_1_5.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_1_5_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_1_5 = CoherenceModel(model=model_1_5, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_1_5 = coherence_model_1_5.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_1_5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r0vCuXc7UPaY",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_1_5, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o2kDlV8p9nyk"
      },
      "source": [
        "#####1.6 Topics = 35"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DePHnNh2930C",
        "colab": {}
      },
      "source": [
        "# Coherence score jumped back to 0.39, let's try 35 topics\n",
        "# Timing Start\n",
        "model_1_6_start_time = time.time()\n",
        "\n",
        "model_1_6 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=35,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=10)\n",
        "\n",
        "# Timing End\n",
        "model_1_6_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p7uVBpVs-KqQ",
        "colab": {}
      },
      "source": [
        "#Printing First Model Time\n",
        "model_1_6_runtime = round(model_1_6_end_time - model_1_6_start_time, 2)\n",
        "print(model_1_6_runtime)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P4W3AFMM-Kwb",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_1_6 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_1_6.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_1_6 = [' '.join(t[0:10]) for t in words_1_6]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_1_6): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zNZ-mZMX-a3S",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_1_6_perplexity = model_1_6.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_1_6_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_1_6 = CoherenceModel(model=model_1_6, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_1_6 = coherence_model_1_6.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_1_6)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HVfKsnZw-5FX",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_1_6, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rEeAdBhD9njQ"
      },
      "source": [
        "#####1.7 Topics = 40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Pp1noqP_c5A",
        "colab": {}
      },
      "source": [
        "# Let's try 40 topics\n",
        "# Timing Start\n",
        "model_1_7_start_time = time.time()\n",
        "\n",
        "model_1_7 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=40,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=10)\n",
        "\n",
        "# Timing End\n",
        "model_1_7_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "617Wp7gq_p9A",
        "colab": {}
      },
      "source": [
        "#Printing First Model Time\n",
        "model_1_7_runtime = round(model_1_7_end_time - model_1_7_start_time, 2)\n",
        "print(model_1_7_runtime)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sLXhWO5P_tWh",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_1_7 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_1_7.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_1_7 = [' '.join(t[0:10]) for t in words_1_7]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_1_7): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eZHLs1mU_12_",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_1_7_perplexity = model_1_7.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_1_7_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_1_7 = CoherenceModel(model=model_1_7, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_1_7 = coherence_model_1_7.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_1_7)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VXDdj7QK_8sG",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_1_7, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kxOIxBma359M"
      },
      "source": [
        "#####1.8 Topics = 5-200\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VKsSbJbWnJ8y",
        "colab": {}
      },
      "source": [
        "#Defining a function to loop over number of topics to be used to find an \n",
        "#optimal number of tipics\n",
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the \n",
        "    LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values_topic = []\n",
        "    model_list_topic = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model_list_topic.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values_topic.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list_topic, coherence_values_topic      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l2Cf4lJmnpdY",
        "colab": {}
      },
      "source": [
        "# Can take a long time to run.\n",
        "model_1_8_start_time = time.time()\n",
        "\n",
        "model_list_topic, coherence_values_topic = compute_coherence_values(dictionary=id2word,\n",
        "                                                        corpus=corpus,\n",
        "                                                        texts=df['lemma_tokens'],\n",
        "                                                        start=2, limit=200, step=6)\n",
        "model_1_8_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VlTYn4sw4vmD",
        "colab": {}
      },
      "source": [
        "#Printing First Model Time\n",
        "model_1_8_runtime = round(model_1_8_end_time - model_1_8_start_time, 2)\n",
        "print(model_1_8_runtime)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XaVFrTZevPzj",
        "colab": {}
      },
      "source": [
        "limit=200; start=2; step=6;\n",
        "x_topic = range(start, limit, step)\n",
        "\n",
        "topic_ts = {'coherence_value': coherence_values_topic,\n",
        "            'number_of_topics': x_topic}\n",
        "\n",
        "topic_chart = pd.DataFrame(data=topic_ts)\n",
        "\n",
        "topic_fig = px.line(topic_chart, x=\"number_of_topics\", y=\"coherence_value\")\n",
        "topic_fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KPu9TOriBNyz",
        "colab": {}
      },
      "source": [
        "#Saving track sheet chart on chart studios to be used in documentation\n",
        "py.plot(topic_fig, filename = 'num_of_topics_chart', auto_open=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7w5nustt6WrB"
      },
      "source": [
        "#####1.9 Topics = 68"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8ciI7vUd6Ewc",
        "colab": {}
      },
      "source": [
        "# Based on 1.8 the optimal number of topics are 68\n",
        "# Timing Start\n",
        "model_1_9_start_time = time.time()\n",
        "\n",
        "model_1_9 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=68,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=10)\n",
        "\n",
        "# Timing End\n",
        "model_1_9_end_time = time.time()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_BksRCtL7sSW",
        "colab": {}
      },
      "source": [
        "#Printing First Model Time\n",
        "model_1_9_runtime = round(model_1_9_end_time - model_1_9_start_time, 2)\n",
        "print(model_1_9_runtime)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MqHNLC747sKP",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_1_9 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_1_9.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_1_9 = [' '.join(t[0:10]) for t in words_1_9]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_1_9): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VJsHrYP-7r7n",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_1_9_perplexity = model_1_9.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_1_9_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_1_9 = CoherenceModel(model=model_1_9, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_1_9 = coherence_model_1_9.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_1_9)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WfH3F_0d8Oz3",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_1_9, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UJSq9fAlnj0H"
      },
      "source": [
        "##### Track Sheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NJ4ubz5fMb41",
        "colab": {}
      },
      "source": [
        "# Let's keep track of our progress\n",
        "\n",
        "topic_ts = {'model_iteration':[1,1,1,1,1,1,1,1,1,1],\n",
        "            'model': [0.0,1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.9],\n",
        "      'runtime_seconds': [base_model_runtime, model_1_0_runtime,\n",
        "                          model_1_1_runtime, model_1_2_runtime,\n",
        "                          model_1_3_runtime, model_1_4_runtime,\n",
        "                          model_1_5_runtime, model_1_6_runtime,\n",
        "                          model_1_7_runtime, model_1_9_runtime],\n",
        "      'coherence_score': [coherence_lda_model_base, coherence_lda_model_1_0,\n",
        "                          coherence_lda_model_1_1, coherence_lda_model_1_2,\n",
        "                          coherence_lda_model_1_3, coherence_lda_model_1_4,\n",
        "                          coherence_lda_model_1_5, coherence_lda_model_1_6,\n",
        "                          coherence_lda_model_1_7, coherence_lda_model_1_9],\n",
        "      'perplexity': [base_perplexity, model_1_0_perplexity, \n",
        "                     model_1_1_perplexity, model_1_2_perplexity,\n",
        "                     model_1_3_perplexity, model_1_4_perplexity,\n",
        "                     model_1_5_perplexity, model_1_6_perplexity,\n",
        "                     model_1_7_perplexity, model_1_9_perplexity],\n",
        "      'number_of_topics': [base_model.num_topics, model_1_0.num_topics,\n",
        "                           model_1_1.num_topics, model_1_2.num_topics,\n",
        "                           model_1_3.num_topics, model_1_4.num_topics, \n",
        "                           model_1_5.num_topics, model_1_6.num_topics,\n",
        "                           model_1_7.num_topics, model_1_9.num_topics],\n",
        "            'passes': [base_model.passes, model_1_0.passes,\n",
        "                           model_1_1.passes, model_1_2.passes,\n",
        "                           model_1_3.passes, model_1_4.passes, \n",
        "                           model_1_5.passes, model_1_6.passes,\n",
        "                           model_1_7.passes, model_1_9.passes]}\n",
        "\n",
        "topic_track_sheet = pd.DataFrame(data=topic_ts)\n",
        "\n",
        "topic_track_sheet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cM7VzuB0VJdf",
        "colab": {}
      },
      "source": [
        "#Visualizing our progress\n",
        "topic_fig_1 = px.line(topic_track_sheet, x=\"number_of_topics\", y=\"coherence_score\",\n",
        "                    hover_name='perplexity', )\n",
        "topic_fig_1.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jp4MyQLTAs8f",
        "colab": {}
      },
      "source": [
        "#Saving track sheet chart on chart studios to be used in documentation\n",
        "py.plot(topic_fig_1, filename = 'num_of_topics', auto_open=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y6SWZ108GhV5"
      },
      "source": [
        "####Model iteration 2 (number of passes)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yeh7DYF8T32z"
      },
      "source": [
        "#####2.0 Passes = 10 \n",
        "*Refer to model 1.3 topics = 20*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cBfsQdRWQCZW"
      },
      "source": [
        "#####2.1 Passes = 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RbgGQvwlBdeC",
        "colab": {}
      },
      "source": [
        "#Chose num_topics=68 based on on the coherence score and the perplexity score\n",
        "#Above 68 will cause the model to overfit and produce non coherent results\n",
        "#Lets try to change passes to asses if it'll improve the coherence score\n",
        "#passes = 15\n",
        "model_2_1_start_time = time.time()\n",
        "\n",
        "model_2_1 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=68,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=10)\n",
        "\n",
        "model_2_1_end_time = time.time()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZifXNNwtXds4",
        "colab": {}
      },
      "source": [
        "model_2_1_runtime = round(model_2_1_end_time - model_2_1_start_time, 2)\n",
        "print(model_2_1_runtime, \"seconds to finish\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wwr0nB7PG4dS",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_2_1 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_2_1.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_2_1 = [' '.join(t[0:10]) for t in words_2_1]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_2_1): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z55_HTV1HGnx",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_2_1_perplexity = model_2_1.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_2_1_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_2_1 = CoherenceModel(model=model_2_1, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_2_1 = coherence_model_2_1.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_2_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SiQBTauyHL_9",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_2_1, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nKm8xOHKRucP"
      },
      "source": [
        "#####2.2 Passes = 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MfsCYYUDYmZO",
        "colab": {}
      },
      "source": [
        "#passes = 20\n",
        "model_2_2_start_time = time.time()\n",
        "\n",
        "model_2_2 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=68,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=20)\n",
        "\n",
        "model_2_2_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NW914zMKYrNE",
        "colab": {}
      },
      "source": [
        "model_2_2_runtime = round(model_2_2_end_time - model_2_2_start_time, 2)\n",
        "print(model_2_2_runtime, \"seconds to finish\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AzK6ElUyYrJb",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_2_2 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_2_2.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_2_2 = [' '.join(t[0:10]) for t in words_2_2]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_2_2): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SlqMJlUPYrG6",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_2_2_perplexity = model_2_2.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_2_2_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_2_2 = CoherenceModel(model=model_2_2, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_2_2 = coherence_model_2_2.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_2_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oz186l5vZFf0",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_2_2, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OSLhtC4iRwUs"
      },
      "source": [
        "#####2.3 Passes = 25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vPRlCworamG6",
        "colab": {}
      },
      "source": [
        "#passes = 20\n",
        "model_2_3_start_time = time.time()\n",
        "\n",
        "model_2_3 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=68,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=25)\n",
        "\n",
        "model_2_3_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LlbxTIfnal9E",
        "colab": {}
      },
      "source": [
        "model_2_3_runtime = round(model_2_3_end_time - model_2_3_start_time, 2)\n",
        "print(model_2_3_runtime, \"seconds to finish\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vt7TZgEUalV9",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_2_3 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_2_3.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_2_3 = [' '.join(t[0:10]) for t in words_2_3]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_2_3): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nTHjxLV0alK_",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_2_3_perplexity = model_2_3.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_2_3_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_2_3 = CoherenceModel(model=model_2_3, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_2_3 = coherence_model_2_3.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_2_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GtFF6GbKalDt",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_2_3, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5lZhBhBwRxIv"
      },
      "source": [
        "#####Track Sheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "toQnIMS5TBj5",
        "colab": {}
      },
      "source": [
        "# Let's keep track of our progress\n",
        "\n",
        "passes_ts = {'model_iteration':[2,2,2,2],\n",
        "             'model': [2.0, 2.1, 2.2, 2.3], \n",
        "      'runtime_seconds': [model_1_9_runtime, model_2_1_runtime,\n",
        "                          model_2_2_runtime, model_2_3_runtime],\n",
        "      'coherence_score': [coherence_lda_model_1_9, coherence_lda_model_2_1, \n",
        "                          coherence_lda_model_2_2, coherence_lda_model_2_3],\n",
        "      'perplexity': [model_1_9_perplexity,model_2_1_perplexity, \n",
        "                     model_2_2_perplexity,model_2_3_perplexity],\n",
        "      'number_of_topics': [model_1_9.num_topics,model_2_1.num_topics, \n",
        "                           model_2_2.num_topics,model_2_3.num_topics],\n",
        "            'passes': [10,15,20,25]}\n",
        "\n",
        "passes_track_sheet = pd.DataFrame(data=passes_ts)\n",
        "\n",
        "passes_track_sheet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B9dpRZb7crds",
        "colab": {}
      },
      "source": [
        "#Visualizing our progress\n",
        "passes_fig = px.line(passes_track_sheet, x=\"passes\", y=\"coherence_score\",\n",
        "                    hover_name='perplexity')\n",
        "passes_fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CkUSsBVJBi02",
        "colab": {}
      },
      "source": [
        "#Saving track sheet chart on chart studios to be used in documentation\n",
        "py.plot(passes_fig, filename = 'passes_track_chart', auto_open=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jx1HX6_hetuf"
      },
      "source": [
        "####Model iteration 3 (Minimum Probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MVLvDaLqgy73"
      },
      "source": [
        "#####3.0 aplpha = symmetric\n",
        "*Refer to model 2.3 passes = 25*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qN1OuZ9GgrIQ"
      },
      "source": [
        "#####3.1 alpha = asymmetric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kcwLhj_ieviX",
        "colab": {}
      },
      "source": [
        "#Chose passes = 25 based on on the coherence score and the perplexity score\n",
        "#Anything above 25 wouldnt significantly improve the scores \n",
        "#Lets try to change alpha to asses if it'll improve the coherence score\n",
        "#alpha = asymmetric\n",
        "model_3_1_start_time = time.time()\n",
        "\n",
        "model_3_1 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=68,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=25,\n",
        "                       alpha = 'asymmetric')\n",
        "\n",
        "model_3_1_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GiisbPamgkIP",
        "colab": {}
      },
      "source": [
        "model_3_1_runtime = round(model_3_1_end_time - model_3_1_start_time, 2)\n",
        "print(model_3_1_runtime, \"seconds to finish\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uRHLAkvWlum_",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_3_1 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_3_1.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_3_1 = [' '.join(t[0:10]) for t in words_3_1]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_3_1): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KDSszquXlywZ",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_3_1_perplexity = model_3_1.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_3_1_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_3_1 = CoherenceModel(model=model_3_1, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_3_1 = coherence_model_3_1.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_3_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9aXD6_nLl4Fu",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_3_1, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FbsIjftYi5h6"
      },
      "source": [
        "#####Track Sheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pzoDUcQEjw19",
        "colab": {}
      },
      "source": [
        "# Let's keep track of our progress\n",
        "\n",
        "alpha_ts = {'model_iteration':[3,3],\n",
        "            'model': [3.0, 3.1], \n",
        "      'runtime_seconds': [model_2_3_runtime, model_3_1_runtime],\n",
        "      'coherence_score': [coherence_lda_model_2_3, coherence_lda_model_3_1],\n",
        "      'perplexity': [model_2_3_perplexity,model_3_1_perplexity],\n",
        "      'number_of_topics': [model_2_3.num_topics,model_3_1.num_topics],\n",
        "      'passes': [25,25],\n",
        "      'alpha':['symmetric','asymmetric']}\n",
        "\n",
        "alpha_track_sheet = pd.DataFrame(data=alpha_ts)\n",
        "\n",
        "alpha_track_sheet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SaegMSjrgL-7"
      },
      "source": [
        "####Model iteration 4 (Decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Z9KbgN6wdAF"
      },
      "source": [
        "#####4.0 Decay = 0.5\n",
        "*Reffer to 2.3*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "geL90uwXw0lK"
      },
      "source": [
        "#####4.1 Decay = 0.7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wf8jEvhhfmuk",
        "colab": {}
      },
      "source": [
        "model_4_1_start_time = time.time()\n",
        "\n",
        "model_4_1 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=68,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=25,\n",
        "                       decay=0.7)\n",
        "\n",
        "model_4_1_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ucpE3Zpql_zH",
        "colab": {}
      },
      "source": [
        "model_4_1_runtime = round(model_4_1_end_time - model_4_1_start_time, 2)\n",
        "print(model_4_1_runtime, \"seconds to finish\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_MaGxKemAWw",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_4_1 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_4_1.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_4_1 = [' '.join(t[0:10]) for t in words_4_1]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_4_1): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cuA7j5ZZmAcJ",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_4_1_perplexity = model_4_1.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_4_1_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_4_1 = CoherenceModel(model=model_4_1, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_4_1 = coherence_model_4_1.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_4_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wyw3MSx6mAhx",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_4_1, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qWj3J_VrxjZc"
      },
      "source": [
        "#####4.2 Decay = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "72gBauLYxqz_",
        "colab": {}
      },
      "source": [
        "model_4_2_start_time = time.time()\n",
        "\n",
        "model_4_2 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=68,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=25,\n",
        "                       decay=0.9)\n",
        "\n",
        "model_4_2_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V5Xe4saCxqxo",
        "colab": {}
      },
      "source": [
        "model_4_2_runtime = round(model_4_2_end_time - model_4_2_start_time, 2)\n",
        "print(model_4_2_runtime, \"seconds to finish\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TOn3gMxAxrmq",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_4_2 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_4_2.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_4_2 = [' '.join(t[0:10]) for t in words_4_2]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_4_2): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QVKTJOKixrkw",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_4_2_perplexity = model_4_2.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_4_2_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_4_2 = CoherenceModel(model=model_4_2, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_4_2 = coherence_model_4_2.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_4_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DClgIwFTxrhi",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_4_2, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kWJVSP2Fys9B"
      },
      "source": [
        "#####Track Sheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5PyJ0KY2y3Wg",
        "colab": {}
      },
      "source": [
        "# Let's keep track of our progress\n",
        "\n",
        "decay_ts = {'model_iteration':[4,4,4],\n",
        "            'model': [4.0, 4.1, 4.2], \n",
        "      'runtime_seconds': [model_2_3_runtime, model_4_1_runtime, \n",
        "                          model_4_2_runtime],\n",
        "      'coherence_score': [coherence_lda_model_2_3, coherence_lda_model_4_1,\n",
        "                          coherence_lda_model_4_2],\n",
        "      'perplexity': [model_2_3_perplexity,model_4_1_perplexity,\n",
        "                     model_4_2_perplexity],\n",
        "      'number_of_topics': [model_2_3.num_topics,model_4_1.num_topics,\n",
        "                           model_4_2.num_topics],\n",
        "      'passes': [model_2_3.passes, model_4_1.passes, model_4_2.passes],\n",
        "      'alpha':['symmetric','symmetric','symmetric'],\n",
        "      'decay':[model_2_3.decay, model_4_1.decay, model_4_2.decay]}\n",
        "\n",
        "decay_track_sheet = pd.DataFrame(data=decay_ts)\n",
        "\n",
        "decay_track_sheet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C1QR9IVM0gTS",
        "colab": {}
      },
      "source": [
        "#Visualizing our progress\n",
        "decay_fig = px.line(decay_track_sheet, x=\"decay\", y=\"coherence_score\",\n",
        "                    hover_name='perplexity')\n",
        "decay_fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Eepn0RzsCrbi",
        "colab": {}
      },
      "source": [
        "#Saving track sheet chart on chart studios to be used in documentation\n",
        "py.plot(decay_fig, filename = 'decay_track_chart', auto_open=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SNQ7edGS4IVu"
      },
      "source": [
        "####Model iteration 5 (iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b2lO9Cx-4QP5"
      },
      "source": [
        "#####5.0 iterations = 50 \n",
        "*refer to 2.3*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W1bhc75P4Y9w"
      },
      "source": [
        "#####5.1 iterations = 60"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qgkpirXW4j5X",
        "colab": {}
      },
      "source": [
        "model_5_1_start_time = time.time()\n",
        "\n",
        "model_5_1 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=68,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=25,\n",
        "                       decay=0.5,\n",
        "                       iterations=60)\n",
        "\n",
        "model_5_1_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4PsSWGPm4nkF",
        "colab": {}
      },
      "source": [
        "model_5_1_runtime = round(model_5_1_end_time - model_5_1_start_time, 2)\n",
        "print(model_5_1_runtime, \"seconds to finish\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8e2RYm2P4_EE",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_5_1 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_5_1.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_5_1 = [' '.join(t[0:10]) for t in words_5_1]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_5_1): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o2fHWAs45FiA",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_5_1_perplexity = model_5_1.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_5_1_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_5_1 = CoherenceModel(model=model_5_1, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_5_1 = coherence_model_5_1.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_5_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d_XDqoV55MT4",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_5_1, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fQIC35LD4dun"
      },
      "source": [
        "#####5.2 iterations = 70"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f-n_wcz34YDH",
        "colab": {}
      },
      "source": [
        "model_5_2_start_time = time.time()\n",
        "\n",
        "model_5_2 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=68,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=25,\n",
        "                       decay=0.5,\n",
        "                       iterations=70)\n",
        "\n",
        "model_5_2_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H8iFHkvP5b9D",
        "colab": {}
      },
      "source": [
        "model_5_2_runtime = round(model_5_2_end_time - model_5_2_start_time, 2)\n",
        "print(model_5_2_runtime, \"seconds to finish\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jtxEiEJn5buA",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_5_2 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_5_2.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_5_2 = [' '.join(t[0:10]) for t in words_5_2]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_5_2): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bi_mgnDh5bg6",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_5_2_perplexity = model_5_2.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_5_2_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_5_2 = CoherenceModel(model=model_5_2, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_5_2 = coherence_model_5_2.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_5_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tgAdcmZP5bV0",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_5_2, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i2WRNLlvLino"
      },
      "source": [
        "#####5.3 iterations = 70-150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hrDJx5z-L1S9",
        "colab": {}
      },
      "source": [
        "#Defining a function to loop over iterations to find an optimal number of tipics\n",
        "def compute_coherence_values_1(dictionary, corpus, texts, limit, start=70, step=10):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of iterations\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of iterations\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the \n",
        "    LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values_its = []\n",
        "    model_list_its = []\n",
        "    for iterations in range(start, limit, step):\n",
        "        model = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=68,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=25,\n",
        "                       decay=0.5,\n",
        "                       iterations=iterations)\n",
        "        model_list_its.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values_its.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list_its, coherence_values_its   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YLVb9yFFMZ1c",
        "colab": {}
      },
      "source": [
        "# Can take a long time to run.\n",
        "model_5_3_start_time = time.time()\n",
        "\n",
        "model_list_its, coherence_values_its = compute_coherence_values_1(dictionary=id2word,\n",
        "                                                        corpus=corpus,\n",
        "                                                        texts=df['lemma_tokens'],\n",
        "                                                        start=70, limit=150, step=10)\n",
        "model_5_3_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "91qwg9A-MtuE",
        "colab": {}
      },
      "source": [
        "#Printing First Model Time\n",
        "model_5_3_runtime = round(model_5_3_end_time - model_5_3_start_time, 2)\n",
        "print(model_5_3_runtime)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AvIf4Tu4NAjM",
        "colab": {}
      },
      "source": [
        "limit=150; start=70; step=10;\n",
        "x_2 = range(start, limit, step)\n",
        "\n",
        "its_ts = {'coherence_value': coherence_values_its,\n",
        "            'number_of_iterations': x_2}\n",
        "\n",
        "its_track_sheet = pd.DataFrame(data=its_ts)\n",
        "\n",
        "its_fig = px.line(its_track_sheet, x=\"number_of_iterations\", y=\"coherence_value\")\n",
        "its_fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vrz4wxQxC2xF",
        "colab": {}
      },
      "source": [
        "#Saving track sheet chart on chart studios to be used in documentation\n",
        "py.plot(its_fig, filename = 'iterations_track_chart', auto_open=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hsbWqUNE6PMP"
      },
      "source": [
        "#####Track Sheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M0FQ3T2i6VdT",
        "colab": {}
      },
      "source": [
        "# Let's keep track of our progress\n",
        "\n",
        "iterations_ts = {'model_iteration':[5,5,5],\n",
        "                 'model': [5.0, 5.1, 5.2], \n",
        "      'runtime_seconds': [model_2_3_runtime, model_5_1_runtime, \n",
        "                          model_5_2_runtime],\n",
        "      'coherence_score': [coherence_lda_model_2_3, coherence_lda_model_5_1,\n",
        "                          coherence_lda_model_5_2],\n",
        "      'perplexity': [model_2_3_perplexity,model_5_1_perplexity,\n",
        "                     model_5_2_perplexity],\n",
        "      'number_of_topics': [model_2_3.num_topics,model_5_1.num_topics,\n",
        "                           model_5_2.num_topics],\n",
        "      'passes': [model_2_3.passes, model_5_1.passes, model_5_2.passes],\n",
        "      'alpha':['symmetric','symmetric','symmetric'],\n",
        "      'decay':[model_2_3.decay, model_5_1.decay, model_5_2.decay],\n",
        "      'iterations':[model_2_3.iterations, model_5_1.iterations,\n",
        "                    model_5_2.iterations]}\n",
        "\n",
        "iterations_track_sheet = pd.DataFrame(data=iterations_ts)\n",
        "\n",
        "iterations_track_sheet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "txQ3cT5OOLDI",
        "colab": {}
      },
      "source": [
        "#Visualizing our progress\n",
        "iterations_fig = px.line(iterations_track_sheet, x=\"iterations\", y=\"coherence_score\",\n",
        "                    hover_name='perplexity')\n",
        "iterations_fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FfZELiMlDBUF",
        "colab": {}
      },
      "source": [
        "#Saving track sheet chart on chart studios to be used in documentation\n",
        "py.plot(iterations_fig, filename = 'iterations_track_chart', auto_open=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cc9diXP4U5nm"
      },
      "source": [
        "####Model iteration 6 (minimum_probability)\n",
        "*eval_every – Log perplexity is estimated every that many updates. Setting this to one slows down training by ~2x.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ejVAGbenVMov"
      },
      "source": [
        "#####6.0 minimum_probability = 0.01\n",
        "*Reffer to 5.2*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uNETvv43VV1V"
      },
      "source": [
        "#####6.1 minimum_probability = 0.05\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8prkPjc1U46q",
        "colab": {}
      },
      "source": [
        "model_6_1_start_time = time.time()\n",
        "\n",
        "model_6_1 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=68,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=25,\n",
        "                       decay=0.5,\n",
        "                       iterations=70,\n",
        "                       minimum_probability=0.05)\n",
        "\n",
        "model_6_1_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3olhGAcmVzC_",
        "colab": {}
      },
      "source": [
        "model_6_1_runtime = round(model_6_1_end_time - model_6_1_start_time, 2)\n",
        "print(model_6_1_runtime, \"seconds to finish\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6BeIEfBeWEW6",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_6_1 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_6_1.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_6_1 = [' '.join(t[0:10]) for t in words_6_1]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_6_1): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P9FKl1TUWEUN",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_6_1_perplexity = model_6_1.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_6_1_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_6_1 = CoherenceModel(model=model_6_1, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_6_1 = coherence_model_6_1.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_6_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BsHZr0uYWERy",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_6_1, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jqXhHLCUt2P9"
      },
      "source": [
        "#####6.2 minimum_probability = 0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VWdOHILKujmx",
        "colab": {}
      },
      "source": [
        "model_6_2_start_time = time.time()\n",
        "\n",
        "model_6_2 = LdaMulticore(corpus=corpus,\n",
        "                       id2word=id2word,\n",
        "                       num_topics=68,\n",
        "                       random_state=42,\n",
        "                       chunksize=2000,\n",
        "                       passes=25,\n",
        "                       decay=0.5,\n",
        "                       iterations=70,\n",
        "                       minimum_probability=0.1)\n",
        "\n",
        "model_6_2_end_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kyb1ueJQurbF",
        "colab": {}
      },
      "source": [
        "model_6_2_runtime = round(model_6_2_end_time - model_6_2_start_time, 2)\n",
        "print(model_6_2_runtime, \"seconds to finish\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vYaC-gHqurSG",
        "colab": {}
      },
      "source": [
        "# Filtering for words \n",
        "words_6_2 = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_6_2.print_topics()]\n",
        "\n",
        "# Create Topics\n",
        "topics_6_2 = [' '.join(t[0:10]) for t in words_6_2]\n",
        "\n",
        "# Getting the topics\n",
        "for id, t in enumerate(topics_6_2): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XIuEQxAzurGj",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# a measure of how good the model is. lower the better\n",
        "model_6_2_perplexity = model_6_2.log_perplexity(corpus)\n",
        "print('\\nPerplexity: ', model_6_2_perplexity) \n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_6_2 = CoherenceModel(model=model_6_2, texts=df['lemma_tokens'], \n",
        "                                   dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_model_6_2 = coherence_model_6_2.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_model_6_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fvB-MU0PvPa2",
        "colab": {}
      },
      "source": [
        "#Creating Topic Distance Visualization \n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(model_6_2, corpus, id2word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9pA-SL4puUuJ"
      },
      "source": [
        "#####Track Sheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4j0PzDZ1uX1Q",
        "colab": {}
      },
      "source": [
        "# Let's keep track of our progress\n",
        "\n",
        "minimum_probability_ts = {'model_iteration':[6,6,6],\n",
        "                          'model': [6.0, 6.1, 6.2], \n",
        "      'runtime_seconds': [model_5_2_runtime, model_6_1_runtime, \n",
        "                          model_6_2_runtime],\n",
        "      'coherence_score': [coherence_lda_model_5_2, coherence_lda_model_6_1,\n",
        "                          coherence_lda_model_6_2],\n",
        "      'perplexity': [model_5_2_perplexity,model_6_1_perplexity,\n",
        "                     model_6_2_perplexity],\n",
        "      'number_of_topics': [model_5_2.num_topics,model_6_1.num_topics,\n",
        "                           model_6_2.num_topics],\n",
        "      'passes': [model_5_2.passes, model_6_1.passes, model_6_2.passes],\n",
        "      'alpha':['symmetric','symmetric','symmetric'],\n",
        "      'decay':[model_5_2.decay, model_6_1.decay, model_6_2.decay],\n",
        "      'iterations':[model_5_2.iterations, model_6_1.iterations,\n",
        "                    model_6_2.iterations],\n",
        "      'minimum_probability':[model_5_2.minimum_probability, \n",
        "                             model_6_1.minimum_probability,\n",
        "                             model_6_2.minimum_probability]}\n",
        "\n",
        "minimum_probability_track_sheet = pd.DataFrame(data=minimum_probability_ts)\n",
        "\n",
        "minimum_probability_track_sheet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y0ix1HffwvQ-",
        "colab": {}
      },
      "source": [
        "#Visualizing our progress\n",
        "minimum_probability_fig = px.line(minimum_probability_track_sheet, x=\"minimum_probability\", y=\"coherence_score\",\n",
        "                    hover_name='perplexity')\n",
        "minimum_probability_fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MGXneVB5D1DW",
        "colab": {}
      },
      "source": [
        "#Saving track sheet chart on chart studios to be used in documentation\n",
        "py.plot(minimum_probability_fig, filename = 'minproba_track_chart', auto_open=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KUWjYue4CZeF",
        "colab": {}
      },
      "source": [
        "end_of_notebook_time = time.time()\n",
        "total_notebook_time_seconds = end_of_notebook_time - start_of_notebook_time\n",
        "total_running_time_of_notebook_minutes = (end_of_notebook_time - start_of_notebook_time) / 60\n",
        "print('Duration for the entire notebook to run: {} seconds.'.format(total_notebook_time_seconds))\n",
        "print(f'Which is {total_running_time_of_notebook_minutes} minutes.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7H0hGikQih-F"
      },
      "source": [
        "####Gensim Mallet 🧛"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sIlhEASAjjxl",
        "colab": {}
      },
      "source": [
        " #Loading Mallet LDA Model\n",
        " from google.colab import files \n",
        " uploaded=files.upload()\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M2caJVLJpNGD",
        "colab": {}
      },
      "source": [
        "!unzip mallet.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "riohnFm9qmyY",
        "colab": {}
      },
      "source": [
        "# lemmas_df = df['lemmas_back_to_text']\n",
        "# vectorizer = CountVectorizer()\n",
        "# data_vectorized = vectorizer.fit_transform(df['lemmas_back_to_text'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uLkq8zrUjjv0",
        "colab": {}
      },
      "source": [
        "from gensim.models.wrappers import LdaMallet\n",
        "# Assigning the mallet path and runnig the mallet model using\n",
        "# the final chosen hyper parameters \n",
        "mallet_path = !/content/mallet/binn/mallett\n",
        "mallet_path\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "mallet_path = r'mallet-2.0.8/bin/mallet'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.exists(mallet_path):\n",
        "    print('{} not found'.format(mallet_path))\n",
        "    sys.exit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QRkzubrwjjr-",
        "colab": {}
      },
      "source": [
        "ldamallet = LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tQjZnQa5jjpk",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AQsvc2zNrYvm"
      },
      "source": [
        "####Progress Tracksheet 🧑‍🔬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8_NgTMETeMYp",
        "colab": {}
      },
      "source": [
        "track_sheet = pd.concat([topic_track_sheet, passes_track_sheet, alpha_track_sheet,\n",
        "                         decay_track_sheet, iterations_track_sheet, \n",
        "                         minimum_probability_track_sheet], ignore_index=True)\n",
        "\n",
        "track_sheet[['alpha', 'decay', \n",
        "             'minimum_probability',\n",
        "             'iterations']] = track_sheet[['alpha', \n",
        "                                           'decay', \n",
        "                                           'minimum_probability',\n",
        "                                           'iterations']].fillna(method='backfill')\n",
        "\n",
        "track_sheet['model_iteration_str'] = track_sheet['model_iteration'].replace(\n",
        "    [1,2,3,4,5,6],['one', 'two', 'three', 'four', 'five', 'six'])\n",
        "\n",
        "track_sheet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1hjcz5db3GVO",
        "colab": {}
      },
      "source": [
        "#Visualizing our progress\n",
        "track_sheet_fig = px.line(track_sheet, x=\"model\", y=\"coherence_score\",\n",
        "                    hover_name='perplexity')\n",
        "track_sheet_fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yoYt_2LP8gAm",
        "colab": {}
      },
      "source": [
        "#Saving track sheet chart on chart studios to be used in documentation\n",
        "py.plot(track_sheet, filename = 'track_chart', auto_open=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z37tu0ypMU2k",
        "colab": {}
      },
      "source": [
        "#Visualizing our progress\n",
        "fig1 = px.scatter(track_sheet, x=\"model\", y=\"coherence_score\", \n",
        "                  color='model_iteration', size='runtime_seconds', \n",
        "                  marginal_y='histogram', marginal_x='violin')\n",
        "\n",
        "fig1.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uY5lDAvd-aKY",
        "colab": {}
      },
      "source": [
        "fig2 = px.scatter(track_sheet, y=\"perplexity\", x=\"coherence_score\", \n",
        "                  color='model_iteration', size='runtime_seconds', \n",
        "                  marginal_y='histogram', marginal_x='violin')\n",
        "\n",
        "fig2.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RP_gqd6cKMNg",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}